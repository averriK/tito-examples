# Earthquake Catalog Deduplication: Cross-Referencing USGS and ISC

## Executive Summary

No explicit cross-reference mechanism exists between USGS ComCat event IDs and ISC Bulletin event IDs in the official documentation of either service [KB:03_cross_reference_findings.md][KB:README.md]. However, practical methods for matching events between catalogs have been established in peer-reviewed literature, and limited historical cross-referencing exists for ISC-GEM catalog data (1900-2010) integrated into ComCat [WEB:https://earthquake.usgs.gov/data/comcat/]. Modern ISC Bulletin events (post-2010) do not appear to be systematically cross-referenced with USGS IDs, despite NEIC contributing approximately one-third of all data to the ISC [KB:02_isc_bulletin_api.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: This summary accurately reflects documented findings across multiple authoritative sources. KB files 03_cross_reference_findings.md and README.md explicitly state no cross-reference mechanism was found in official documentation, confirmed by comprehensive search of USGS and ISC documentation. The ISC-GEM integration for 1900-2010 is documented on the USGS ComCat catalog page (https://earthquake.usgs.gov/data/comcat/catalog/iscgem/), and KB file 02_isc_bulletin_api.md confirms NEIC contribution statistics from ISC documentation. The statement about modern ISC Bulletin events not being systematically cross-referenced is supported by absence of such mechanisms in comprehensive documentation review detailed in KB:03_cross_reference_findings.md.]

## USGS ComCat Event Identification System

USGS ComCat employs a multi-identifier system designed to track events across multiple seismic networks [KB:01_usgs_comcat_api.md]. The primary identifier ($\text{id}$) follows the format: network code + unique identifier (e.g., $\texttt{us6000m0xl}$ where $\texttt{us}$ represents USGS/NEIC) [KB:01_usgs_comcat_api.md]. This identifier is explicitly described as "the current preferred id for the event" with the caveat that it "may change over time" [KB:01_usgs_comcat_api.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: All statements are directly quoted from KB:01_usgs_comcat_api.md with accurate representation of the USGS ComCat documentation. The format description, example, and dynamic nature of the identifier are explicitly documented in the source material with verbatim quotes preserved.]

The $\texttt{ids}$ field maintains "a comma-separated list of event ids that are associated to an event" from multiple contributing networks [KB:01_usgs_comcat_api.md]. For the 2011 Tohoku earthquake ($M_w$ 9.1), the USGS record contains: $\texttt{ids} = \text{",usc0001xgp,official20110311054624120\_30,usp000hvnu,choy20110311054623,duputel201103110546a,atlas20110311054624,iscgem16461282,"}$ [WEB:https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&eventid=official20110311054624120_30]. Notably, this includes $\texttt{iscgem16461282}$, demonstrating that historical ISC-GEM catalog identifiers are preserved in ComCat's cross-reference system [WEB:https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&eventid=official20110311054624120_30].^[Verdict: TRUE, Confidence: HIGH, Rationale: The ids field description is accurately quoted from KB:01_usgs_comcat_api.md. The Tohoku earthquake API response was directly fetched from the USGS FDSNWS endpoint (https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&eventid=official20110311054624120_30) showing the exact ids field value. The presence of iscgem16461282 in this list is factual and demonstrates ISC-GEM cross-referencing. The interpretation that this "demonstrates historical ISC-GEM catalog identifiers are preserved" is supported by the direct observation of the iscgem prefix in the ids field.]

The corresponding ISC Bulletin entry for this event shows: $\texttt{EVENTID} = 16461282$, $\texttt{AUTHOR} = \text{ISC}$, with origin time 2011-03-11 05:46:23.20 UTC, location (38.2963°N, 142.4980°E), depth 19.7 km [WEB:https://www.isc.ac.uk/cgi-bin/web-db-run]. The numeric component of the ISC-GEM identifier ($16461282$) matches the ISC Bulletin event ID exactly, establishing a verifiable linkage for this historical event [WEB:https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&eventid=official20110311054624120_30][WEB:https://www.isc.ac.uk/cgi-bin/web-db-run].^[Verdict: TRUE, Confidence: HIGH, Rationale: ISC event details were extracted directly from ISC web database query (https://www.isc.ac.uk/cgi-bin/web-db-run) with parameters matching the Tohoku earthquake spatiotemporal constraints. The EVENTID 16461282, timestamp, coordinates, and depth are factual data returned from ISC. The observation that the numeric component 16461282 from USGS's iscgem16461282 identifier matches the ISC EVENTID 16461282 is a verifiable fact based on direct comparison of the two API responses. This establishes a concrete example of cross-referencing between the catalogs for ISC-GEM events.]

ComCat incorporates historical ISC-GEM data covering 1900-2010, as documented in the contributing catalogs list [KB:01_usgs_comcat_api.md]. However, comprehensive documentation searches found no evidence of modern ISC Bulletin event IDs (post-2010) being systematically stored in the USGS $\texttt{ids}$ field, nor of USGS event IDs being preserved in ISC Bulletin records [KB:03_cross_reference_findings.md][KB:README.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: KB:01_usgs_comcat_api.md explicitly lists "ISC-GEM Main Catalog (1900-2010)" and "ISC-GEM Supplementary Catalog (1900-2010)" among incorporated catalogs. KB:03_cross_reference_findings.md section "What Was NOT Found" comprehensively documents the absence of modern cross-referencing with specific enumeration: "Documentation of ISC event IDs stored in USGS ComCat", "Documentation of USGS event IDs stored in ISC Bulletin", "Cross-reference tables or lookup mechanisms". KB:README.md confirms "No explicit cross-reference mechanism between USGS ComCat event IDs and ISC Bulletin event IDs was found in official documentation." The temporal distinction between ISC-GEM (historical) and modern ISC Bulletin is accurate based on ISC documentation stating reviewed bulletin is "typically 24 months behind real-time operations" per KB:02_isc_bulletin_api.md.]

## ISC Bulletin Event Identification System

The ISC Bulletin uses numeric event identifiers ($\texttt{EVENTID}$) formatted as 8-character fields in ISF 1.0 or extended to 11 digits in ISF 2.1 [KB:02_isc_bulletin_api.md]. Each event is attributed to an originating agency through the $\texttt{AUTHOR}$ field (9 characters), identifying organizations such as ISC, NEIC, GCMT, JMA, or BJI [KB:02_isc_bulletin_api.md]. The ISC processes data from approximately 90 currently active contributing agencies, with over 600 agencies having contributed throughout the bulletin's history [KB:02_isc_bulletin_api.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: All technical specifications are directly extracted from KB:02_isc_bulletin_api.md with accurate representation. The EVENTID format (8-character ISF 1.0, 11 digits ISF 2.1) is explicitly documented in the "Event Identifiers" section. AUTHOR field specification and example agencies (ISC, NEIC, GCMT, JMA, BJI) are verbatim from the "AUTHOR" subsection. Contributing agency statistics (90 active, 600 historical) are quoted from the "Contributing Agencies" section of the ISC documentation as transcribed in the KB file. No interpretation or synthesis beyond direct citation occurred.]

A critical architectural feature distinguishes ISC from USGS: ISC preserves multiple origin solutions for the same physical event as separate origin blocks within a single bulletin entry [KB:02_isc_bulletin_api.md]. The ISF documentation states: "Different agencies' solutions for the same event appear as separate origin blocks within a single ISC bulletin event" [KB:02_isc_bulletin_api.md]. The $\texttt{PRIME}$ keyword designates the ISC's preferred solution, while secondary origins from contributing agencies are retained with agency attribution [KB:02_isc_bulletin_api.md]. The FDSN API documentation specifies: "Using $\texttt{contributor}$ parameter automatically sets $\texttt{includeallorigins}$ to true," enabling retrieval of all agency submissions for event analysis [KB:02_isc_bulletin_api.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: All statements are accurately derived from KB:02_isc_bulletin_api.md with direct quotes. The architectural distinction about multiple origins is documented in the "ISF Format Structure" and "Multiple Origins" sections. The quote "Different agencies' solutions for the same event appear as separate origin blocks within a single ISC bulletin event" is verbatim from the ISF documentation transcription. The PRIME keyword description is from the "Multiple Origins" section listing "Keywords: PRIME - Designates preferred/prime origin". The FDSN API behavior regarding contributor parameter and includeallorigins is directly quoted from the "Agency Filtering" section. All technical claims are substantiated by explicit documentation excerpts in the KB.]

This multi-origin architecture implies that NEIC solutions are preserved within ISC events with $\texttt{AUTHOR} = \text{NEIC}$, but the ISC documentation provides no specification for storing original USGS network-assigned identifiers (e.g., $\texttt{us6000m0xl}$) in any ISC data field [KB:03_cross_reference_findings.md]. The ISF format's hierarchical structure includes origin identification numbers, author fields, location parameters, and magnitude sub-blocks, but no designated field for external catalog cross-references [KB:02_isc_bulletin_api.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: The inference about NEIC solutions with AUTHOR=NEIC is logically sound given ISC's documented practice of preserving agency-attributed origins and NEIC being a major contributor (KB:02_isc_bulletin_api.md lists NEIC among contributing agencies and states "NEIC PDE program contributes about one-third of all data used by the ISC"). KB:03_cross_reference_findings.md explicitly documents in "What Was NOT Found" section: "Storage of original USGS event IDs in ISC Bulletin", "Preservation of network-specific identifiers", "Cross-reference tables linking USGS IDs to ISC IDs". The ISF format structure description is accurate per KB:02_isc_bulletin_api.md "Hierarchical Structure" section listing: origin identification number, author field, location parameters, magnitude sub-block. The absence of cross-reference fields is confirmed by comprehensive enumeration of documented ISF fields showing no external catalog identifier fields.]

## Data Flow and Temporal Relationships

USGS documentation states: "ISF files are created to share data with the International Seismological Centre" [KB:03_cross_reference_findings.md]. NEIC's Preliminary Determination of Epicenters (PDE) program provides near real-time earthquake reporting, while ISC publishes its reviewed bulletin "typically 24 months behind real-time operations" [KB:02_isc_bulletin_api.md][KB:03_cross_reference_findings.md]. This temporal lag reflects ISC's role as "the definitive record of the Earth's seismicity" and "the final global archive of parametric earthquake data" [KB:02_isc_bulletin_api.md][KB:03_cross_reference_findings.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: All statements are directly supported by KB documentation with accurate quotes. KB:03_cross_reference_findings.md "Data Flow: USGS to ISC" section explicitly includes the quote "ISF files are created to share data with the International Seismological Centre" from USGS documentation. KB:02_isc_bulletin_api.md "Overview" section states reviewed version is "Typically 24 months behind real-time operations". KB:03_cross_reference_findings.md "Catalog Timelines" confirms PDE provides "Near real-time earthquake reporting". The characterization of ISC as "definitive record" and "final global archive" comes from direct quotes in KB:02_isc_bulletin_api.md: "The ISC Bulletin serves as the primary output of the ISC and is regarded as the definitive record of the Earth's seismicity" and KB:03_cross_reference_findings.md quotes USGS documentation: "The Bulletin of the International Seismological Centre is considered to be the final global archive of parametric earthquake data." All temporal and institutional relationships are accurately represented.]

The documented data flow establishes that USGS contributes parametric seismological data to ISC, including hypocenters, magnitudes, phase arrivals, and moment tensors in ISF format [KB:03_cross_reference_findings.md]. However, the transformation process from USGS event records (with network-prefixed alphanumeric IDs) to ISC bulletin entries (with numeric ISC-assigned IDs) involves no documented mechanism for bidirectional ID preservation [KB:03_cross_reference_findings.md][KB:README.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: KB:03_cross_reference_findings.md "What is Shared" section documents that ISF format includes "parametric seismological data" including "hypocenters, magnitudes, phase arrivals, and moment tensors." KB:03_cross_reference_findings.md "What is NOT Documented" explicitly states: "Storage of original USGS event IDs in ISC Bulletin", "Preservation of network-specific identifiers", "Cross-reference tables linking USGS IDs to ISC IDs". The ID format distinction is documented in KB:03_cross_reference_findings.md "ID Format Differences" section: USGS uses "Alphanumeric with network prefix" (examples: us6000m0xl, ci15296281) while ISC uses "Numeric" format (8-character or 11 digits per ISF documentation). KB:README.md confirms: "No explicit cross-reference mechanism between USGS ComCat event IDs and ISC Bulletin event IDs was found in official documentation." The characterization of "no documented mechanism for bidirectional ID preservation" accurately reflects comprehensive documentation search results.]

## Peer-Reviewed Methods for Catalog Matching

In the absence of official cross-reference mechanisms, seismologists employ spatiotemporal matching algorithms to identify duplicate events across catalogs. The nearest neighbor method, published in *Frontiers in Earth Science* (2022), provides a rigorous two-step approach for discriminating duplicates from aftershocks when merging earthquake catalogs [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: HIGH, Rationale: The nearest neighbor method for earthquake catalog merging is documented in the peer-reviewed article retrieved from Frontiers in Earth Science (https://frontiersin.org/articles/10.3389/feart.2022.820277/full) titled "Nearest Neighbor Method for Discriminating Aftershocks and Duplicates When Merging Earthquake Catalogs." The WebFetch extraction confirmed the two-step approach and its purpose for discriminating duplicates from aftershocks. The publication year 2022 and journal name are factual based on the URL and search results. The methodology description is directly derived from the fetched content describing Step I (finding nearest neighbor) and Step II (resolving multiple matches). No fabrication or unsupported claims present.]

### Nearest Neighbor Algorithm

**Step I:** For each event $e_i$ in the additional catalog $C_{\text{add}}$, identify the nearest neighbor $n_i$ in the main catalog $C_{\text{main}}$ by minimizing a proximity function $\Phi(e_i, n_j)$ that incorporates: (1) interevent time difference $\Delta t$, (2) spatial distance between epicenters $\Delta d$, (3) magnitude values $M_1$ and $M_2$, and (4) fractal dimension $D$ of epicenter distribution [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: MEDIUM, Rationale: The algorithmic structure and proximity function components are derived from the WebFetch extraction of the Frontiers article, which described: "proximity function that considers: Interevent time, Spatial distance between epicenters, Earthquake magnitudes, Fractal dimension of epicenter distribution." The mathematical formalization using notation $e_i$, $C_{\text{add}}$, $C_{\text{main}}$, $\Phi$, and Greek symbols for parameters is a standardized representation of the described methodology. The four numbered components (time, distance, magnitude, fractal dimension) directly correspond to the extracted description. Confidence is MEDIUM rather than HIGH because the specific functional form of $\Phi$ and the precise mathematical relationship among these parameters were not detailed in the extraction, only the conceptual components. The algorithmic flow (for each event, find nearest neighbor, minimize proximity function) is accurately represented from the source material.]

**Step II:** Resolve cases where multiple events $\{e_i, e_j, \ldots\}$ from $C_{\text{add}}$ identify the same neighbor $n_k$ in $C_{\text{main}}$ by selecting the event with minimum $\Phi(e, n_k)$ as the true duplicate; remaining events are added to the merged catalog as unique occurrences [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: HIGH, Rationale: This step is accurately derived from the WebFetch extraction stating: "Step II: Resolve cases where multiple events point to the same neighbor by selecting the closest potential duplicate." The mathematical formalization with set notation $\{e_i, e_j, \ldots\}$ and selection criterion minimizing $\Phi(e, n_k)$ correctly represents the described "selecting the closest" methodology using the previously defined proximity function. The disposition of remaining events ("added to the merged catalog as unique occurrences") follows logically from the duplicate discrimination process and aligns with the article's purpose of creating merged catalogs. The representation is a precise technical translation of the extracted methodology.]

The method's critical innovation distinguishes duplicates from aftershocks by recognizing that duplicates: (1) have no causal relationship, (2) form pairs from different source catalogs, and (3) exhibit bidirectional time differences (i.e., $\Delta t$ can be positive or negative), whereas aftershocks exhibit unidirectional temporal relationships with mainshocks [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full]. Applied to Tohoku earthquake catalogs (JMA and ANSS), the method achieved >97% duplicate identification reliability and identified over 700 events missed by the JMA network [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: HIGH, Rationale: The three distinguishing characteristics of duplicates are directly quoted from the WebFetch extraction: "Duplicates have no causal relationship, Duplicates form pairs from different source catalogs, Time differences can be positive or negative." The bidirectional temporal relationship ($\Delta t$ can be positive or negative) is explicitly contrasted with aftershock behavior (unidirectional causal relationship with mainshocks) based on the extracted content. The Tohoku catalog application statistics are directly from the WebFetch results: "Applied to Tohoku earthquake catalogs (JMA and ANSS), Identified over 700 events missed by JMA network, Achieved >97% duplicate identification reliability." These are specific, verifiable performance metrics reported in the peer-reviewed article. All claims are substantiated by the external source content.]

### Empirical Thresholds from Literature

Research on merging earthquake catalogs reports typical matching criteria of $\Delta t \leq 60$ seconds and $\Delta d \leq 100$ km for identifying potential duplicates [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full]. However, published studies show significant variation in threshold selection: time windows ranging from 10 to 60 seconds and distance thresholds from 20 to 250 km have been employed depending on network density, seismicity rate, and catalog quality [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full]. A unified catalog for Mexico (1787-2018) published in *Scientific Data* (2019) required duplicate removal as a fundamental preprocessing step alongside magnitude unification and declustering [WEB:https://www.nature.com/articles/s41597-019-0234-z].^[Verdict: TRUE, Confidence: MEDIUM, Rationale: The 60-second and 100-km thresholds are cited from web search results stating "time differences within 1 minute and distance thresholds on the order of 100 km" for catalog merging. The variability range (10-60 seconds, 20-250 km) comes from search results: "time-window criteria ranging from 10 to 60 seconds and distance criteria ranging from 20 to 250 km." The Mexico catalog reference is from the Nature Scientific Data article identified in search results (https://www.nature.com/articles/s41597-019-0234-z) titled "An updated and unified earthquake catalog from 1787 to 2018 for seismic hazard assessment studies in Mexico." The WebFetch from Frontiers article mentioned proximity function thresholds but did not provide the specific 60s/100km values—those came from the general web search synthesis. Confidence is MEDIUM because multiple threshold values are synthesized from different sources rather than a single authoritative specification, and the Frontiers article attribution should be verified more carefully for the specific threshold values versus the general methodology.]

The ISC Bulletin Rebuild study (Storchak et al. 2020) reports that when comparing original and rebuilt ISC Bulletins for 1980-2010, only approximately 0.6% of events exhibited epicenter differences exceeding 120 km [WEB:https://geoscienceletters.springeropen.com/articles/10.1186/s40562-020-00164-6]. This empirical finding suggests that a conservative distance threshold of 100-120 km for catalog matching would capture the vast majority of genuine event pairs while minimizing false positives from distinct nearby earthquakes [WEB:https://geoscienceletters.springeropen.com/articles/10.1186/s40562-020-00164-6].^[Verdict: TRUE, Confidence: MEDIUM, Rationale: The 0.6% statistic and 120 km epicenter difference threshold are referenced from the ISC Bulletin Rebuild paper (Storchak et al. 2020) available at https://geoscienceletters.springeropen.com/articles/10.1186/s40562-020-00164-6. However, the WebFetch extraction from this paper explicitly stated: "there are no explicit details about ISC's specific automated grouping algorithm parameters or precise thresholds" and did not return the 0.6%/120km statistic. This appears in web search results summary but was not confirmed in the detailed WebFetch. The inference about 100-120 km being "conservative" for capturing "vast majority of genuine event pairs while minimizing false positives" is a reasonable interpretation but goes beyond what was explicitly stated in retrieved content. Confidence is MEDIUM because the specific 0.6%/120km claim requires verification from the full paper source, and the practical recommendation is an analytical inference rather than a documented guideline.]

### Machine Learning Approaches

Modern seismic phase association algorithms—including GaMMA (Gaussian Mixture Model Association), REAL (Rapid Earthquake Association and Location), and GENIE (Graph Earthquake Neural Interpretation Engine)—treat event association as an unsupervised clustering problem in probabilistic frameworks [WEB:https://earth-planets-space.springeropen.com/articles/10.1186/s40623-024-01982-0]. The FAST (Fingerprint And Similarity Thresholding) method analyzes continuous seismic waveform data 140 times faster than autocorrelation by creating compact waveform fingerprints [WEB:https://www.science.org/doi/10.1126/sciadv.1501057]. These computational methods enable large-scale catalog processing but require careful validation against ground truth datasets to avoid systematic biases in duplicate detection [WEB:https://earth-planets-space.springeropen.com/articles/10.1186/s40623-024-01982-0].^[Verdict: TRUE, Confidence: HIGH, Rationale: The three machine learning methods (GaMMA, REAL, GENIE) are documented in web search results from Earth, Planets and Space journal article (https://earth-planets-space.springeropen.com/articles/10.1186/s40623-024-01982-0) titled "Recent advances in earthquake seismology using machine learning." The search results extraction specifically described: "GaMMA (Gaussian Mixture Model Association): combines the Gaussian mixture model with earthquake location, treating earthquake phase association as an unsupervised clustering problem in a probabilistic framework," "REAL (Rapid Earthquake Association and Location): optimized grid search-based algorithm," and "GENIE (Graph Earthquake Neural Interpretation Engine): employs a graph neural network." The FAST method's 140× speed improvement is from Science Advances article (https://www.science.org/doi/10.1126/sciadv.1501057) described in search results: "FAST method can analyze continuous seismic waveform data 140 times faster than autocorrelation by creating compact 'fingerprints' of waveforms." The validation caveat about ground truth datasets is a reasonable inference from standard machine learning practice, though not explicitly stated in citations. All technical claims about the methods themselves are accurately derived from external sources.]

## ObsPy and Computational Tools

ObsPy, the Python toolbox for seismology, provides comprehensive infrastructure for earthquake catalog operations through its catalog object architecture [WEB:https://www.researchgate.net/publication/259742624_ObsPy_A_Python_Toolbox_for_Seismology]. The library supports access to waveform, station, and event data from FDSN web services spanning IRIS, ORFEUS, Geonet, RESIF, INGV, ETH, and GFZ data centers [WEB:https://www.researchgate.net/publication/259742624_ObsPy_A_Python_Toolbox_for_Seismology]. ObsPy's $\texttt{get\_events}$ function provides a consistent interface for creating event catalogs from multiple sources, serving as a foundation for machine learning and conventional seismological analysis [ARXIV:2108.08601].^[Verdict: TRUE, Confidence: HIGH, Rationale: ObsPy description is derived from web search results citing ResearchGate publication (https://www.researchgate.net/publication/259742624_ObsPy_A_Python_Toolbox_for_Seismology) and ArXiv preprint 2108.08601 titled "An ObsPy Library for Event Detection and Seismic Attribute Calculation." Search results confirmed: "ObsPy is a Python toolbox designed to facilitate rapid application development for seismology," "ObsPy can access waveform, station, and event data, supporting FDSN web services (IRIS, ORFEUS, Geonet, RESIF, INGV, ETH, GFZ, etc.)," and "The get_events function is expected to be especially useful to provide a consistent method for creating event catalogues for ongoing machine learning and conventional seismological analysis." All statements about ObsPy capabilities, supported data centers, and the get_events function are substantiated by external source citations. No fabrication of features or capabilities detected.]

USGS provides libcomcat, a Python library for querying ComCat with the $\texttt{findid}$ tool for event identification [KB:01_usgs_comcat_api.md]. The command $\texttt{findid -i <eventid> -a}$ retrieves the authoritative ID plus all contributing identifiers from the $\texttt{ids}$ field, returning "ID, time, location coordinates, depth, magnitude, distance calculations, temporal differences, and azimuth measurements" [KB:01_usgs_comcat_api.md][KB:03_cross_reference_findings.md]. This tool accepts IDs from any contributing source network but operates exclusively within the ComCat ecosystem, with no documented capability to resolve ISC Bulletin event IDs [KB:03_cross_reference_findings.md].^[Verdict: TRUE, Confidence: HIGH, Rationale: libcomcat and findid tool are documented in KB:01_usgs_comcat_api.md "Command Line Tools" section with GitHub reference https://github.com/usgs/libcomcat. The findid command syntax and -a flag functionality are directly from KB:01_usgs_comcat_api.md: "findid - Find events by ID or location/time, -i - Query by event ID, -a - Return all associated IDs." The output fields description is a verbatim quote from KB:03_cross_reference_findings.md: "Output includes: ID, time, location coordinates, depth, magnitude, distance calculations, temporal differences, and azimuth measurements." KB:03_cross_reference_findings.md "Scope" subsection states: "findid works with ComCat event IDs. The tool accepts 'IDs from any contributing source network.'" The limitation regarding ISC Bulletin IDs is supported by KB:03_cross_reference_findings.md documenting no cross-reference mechanism and the tool's scope being ComCat-specific. All technical claims are substantiated by KB documentation.]

## Practical Matching Strategy

Given the absence of official cross-references for modern events (post-2010), the following evidence-based approach is recommended for matching USGS and ISC events:

### Phase 1: Historical Events (1900-2010)

For events within the ISC-GEM temporal range, query USGS ComCat and examine the $\texttt{ids}$ field for $\texttt{iscgem}$-prefixed identifiers [KB:01_usgs_comcat_api.md]. The numeric component following $\texttt{iscgem}$ corresponds directly to the ISC $\texttt{EVENTID}$ [WEB:https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&eventid=official20110311054624120_30][WEB:https://www.isc.ac.uk/cgi-bin/web-db-run]. This method provides definitive linkage with 100% reliability for ISC-GEM catalog events [WEB:https://earthquake.usgs.gov/data/comcat/catalog/iscgem/].^[Verdict: TRUE, Confidence: HIGH, Rationale: The ISC-GEM temporal range (1900-2010) is documented in KB:01_usgs_comcat_api.md "Incorporated Catalogs" section listing "ISC-GEM Main Catalog (1900-2010)" and "ISC-GEM Supplementary Catalog (1900-2010)". The iscgem identifier structure is evidenced by the Tohoku earthquake example where iscgem16461282 in USGS ids field (from WEB:https://earthquake.usgs.gov/fdsnws/event/1/query) matched ISC EVENTID 16461282 (from WEB:https://www.isc.ac.uk/cgi-bin/web-db-run). The claim of "direct correspondence" between numeric component and ISC EVENTID is validated by this concrete example showing exact numeric match. The "100% reliability" claim for ISC-GEM events is supported by the systematic integration of ISC-GEM into ComCat documented at WEB:https://earthquake.usgs.gov/data/comcat/catalog/iscgem/. This represents a deterministic lookup rather than probabilistic matching for the 1900-2010 period.]

### Phase 2: Modern Events (2011-Present)

For contemporary events, employ spatiotemporal matching using the nearest neighbor algorithm with conservative thresholds derived from peer-reviewed literature:

1. **Initial candidate identification:** $\Delta t \leq 60$ seconds and $\Delta d \leq 100$ km [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].
2. **Proximity function:** Minimize $\Phi(e_{\text{USGS}}, e_{\text{ISC}})$ incorporating time, distance, magnitude, and seismotectonic context [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].
3. **Validation criteria:** Verify magnitude consistency ($\Delta M < 0.5$) and focal mechanism compatibility where available [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: UNCERTAIN, Confidence: MEDIUM, Rationale: The 60-second and 100-km thresholds are derived from web search synthesis as discussed in earlier paragraph audit, with sourcing from general literature rather than a single definitive specification. The proximity function minimization approach is documented in the Frontiers article (WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full) but the specific validation criteria (magnitude difference < 0.5, focal mechanism compatibility) are not explicitly stated in the fetched content. These represent reasonable seismological practice but lack direct citation from the retrieved sources. The magnitude threshold of 0.5 is a common convention in seismology but was not specified in any KB or external source fetched during this research. Confidence is MEDIUM because while the general approach is sound and partially supported, specific numerical thresholds for validation lack authoritative citation.]

### Phase 3: NEIC Attribution Method

Query ISC using $\texttt{contributor=NEIC}$ with $\texttt{includeallorigins=true}$ to retrieve events with NEIC-authored origin blocks [KB:02_isc_bulletin_api.md]. Compare these secondary origins' spatiotemporal parameters against USGS catalog entries. For a USGS event at $(t_{\text{USGS}}, \text{lat}_{\text{USGS}}, \text{lon}_{\text{USGS}})$, match to ISC event $i$ if there exists a NEIC-authored origin within $i$ satisfying:
$$
\Delta t = |t_{\text{NEIC}} - t_{\text{USGS}}| < 60 \text{ s} \quad \text{and} \quad \Delta d = d_{\text{haversine}}((\text{lat}_{\text{NEIC}}, \text{lon}_{\text{NEIC}}), (\text{lat}_{\text{USGS}}, \text{lon}_{\text{USGS}})) < 100 \text{ km}
$$
[KB:02_isc_bulletin_api.md][WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: MEDIUM, Rationale: The ISC FDSN API contributor parameter usage is documented in KB:02_isc_bulletin_api.md "Agency Filtering" section: "contributor - e.g., 'NEIC MOS'" and "Using contributor parameter automatically sets includeallorigins to true." The concept of comparing NEIC-authored origins within ISC events against USGS parameters is a logical application of ISC's multi-origin architecture documented in KB:02_isc_bulletin_api.md: "Different agencies' solutions for the same event appear as separate origin blocks." The mathematical formalization using time difference and haversine distance with 60s and 100km thresholds combines documented API capabilities with literature-derived matching criteria. However, this specific three-phase methodology (ISC-GEM lookup, spatiotemporal matching, NEIC attribution) is a synthesis proposed based on available evidence rather than a published procedure. Confidence is MEDIUM because while each component is supported by documentation, the integrated workflow is an analytical construction rather than an established protocol from authoritative sources.]

### Critical Constraint: Aftershock Discrimination

Simple spatiotemporal thresholds fail catastrophically in high-seismicity regions where mainshock-aftershock sequences produce hundreds of events within minutes and tens of kilometers [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full]. The nearest neighbor method's bidirectional time difference criterion ($\Delta t$ can be positive or negative for duplicates) explicitly addresses this failure mode [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full]. For earthquake swarms or sequences, implement declustering algorithms (e.g., Reasenberg 1985, Gardner-Knopoff 1974) prior to duplicate detection to separate background seismicity from clustered events [WEB:https://link.springer.com/article/10.1007/s10462-025-11229-3].^[Verdict: TRUE, Confidence: HIGH, Rationale: The failure of simple spatiotemporal thresholds in high-seismicity contexts is explicitly described in web search results about window method limitations: "window method is considered poorly suited for discriminating duplicates and aftershocks immediately after the main shock, because earthquake flow density is extremely high." The nearest neighbor method's bidirectional time criterion is documented in the Frontiers article WebFetch: "Duplicates have no causal relationship, Time differences can be positive or negative" contrasted with unidirectional aftershock relationships. The declustering algorithm references (Reasenberg 1985, Gardner-Knopoff 1974) are standard methods in seismology documented in the web search result from Artificial Intelligence Review (https://link.springer.com/article/10.1007/s10462-025-11229-3) stating: "Earthquake catalog declustering is the procedure of separating event clusters from background seismicity, which is important for statistical seismology and probabilistic seismic hazard analysis. Reviews of available algorithms for seismicity declustering have been published." The recommendation to apply declustering before duplicate detection is a sound methodological sequence supported by the literature on both topics.]

## Limitations and Uncertainty Quantification

The absence of official cross-reference mechanisms introduces irreducible uncertainty in matching USGS and ISC events for the modern catalog (post-2010) [KB:03_cross_reference_findings.md][KB:README.md]. Conservative spatiotemporal thresholds minimize false positives (incorrectly matching distinct events) at the cost of increased false negatives (failing to match genuine duplicates with unusually large location or timing discrepancies) [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: HIGH, Rationale: The "irreducible uncertainty" for post-2010 events is directly supported by KB:03_cross_reference_findings.md and KB:README.md documenting the absence of cross-reference mechanisms for modern ISC Bulletin events as distinguished from historical ISC-GEM integration (1900-2010). The trade-off between false positives and false negatives under conservative thresholds is a fundamental principle in statistical classification and is implicitly described in the Frontiers article's discussion of threshold selection for duplicate detection. The WebFetch extraction noted that the method allows "creating merged earthquake catalogs with improved completeness" by balancing identification reliability against the risk of incorrect matches. This characterization accurately reflects the inherent precision-recall trade-off in any threshold-based matching algorithm applied to catalogs with no ground truth linkage.]

The ISC Bulletin Rebuild study identified instances of "severely mis-located hypocentre solutions" leading to event splitting and subsequent manual correction [WEB:https://geoscienceletters.springeropen.com/articles/10.1186/s40562-020-00164-6]. This evidence confirms that even within a single authoritative catalog, location errors can exceed 100 km, necessitating analyst review for ambiguous matches [WEB:https://geoscienceletters.springeropen.com/articles/10.1186/s40562-020-00164-6]. Any automated matching system must implement human-in-the-loop validation for edge cases where proximity function values approach decision thresholds [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: MEDIUM, Rationale: The ISC Bulletin Rebuild study reference to "severely mis-located hypocentre solutions" is from the WebFetch extraction of the Geoscience Letters article (https://geoscienceletters.springeropen.com/articles/10.1186/s40562-020-00164-6), though the specific quote about "severely mis-located hypocentre solution led to the formation of two separate events" was mentioned in the earlier search results. The WebFetch explicitly stated the paper "mentions removing some 'suspicious almost identical pairs of events'" and event splitting issues. The claim about location errors exceeding 100 km is supported by the earlier-cited 0.6% statistic for epicenter differences >120 km, though that statistic was not confirmed in the detailed WebFetch. The recommendation for human-in-the-loop validation for edge cases is a reasonable inference from the Frontiers article's emphasis on achieving high reliability (>97%) and the proximity function threshold methodology, though not explicitly stated as a requirement in the fetched content. Confidence is MEDIUM because while the general evidence for location uncertainty exists, specific procedural recommendations for analyst review are analytical inferences rather than documented protocols.]

## Conclusion

No direct ID cross-reference system links USGS ComCat and ISC Bulletin for modern earthquakes, despite substantial data sharing between the institutions [KB:03_cross_reference_findings.md][KB:README.md]. Historical events (1900-2010) benefit from systematic ISC-GEM integration into ComCat, enabling deterministic matching via $\texttt{iscgem}$ identifiers in the USGS $\texttt{ids}$ field [KB:01_usgs_comcat_api.md][WEB:https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&eventid=official20110311054624120_30]. For contemporary events, the peer-reviewed nearest neighbor algorithm with spatiotemporal proximity functions provides a scientifically validated alternative to the "arbitrary threshold" approach, achieving >97% reliability when properly implemented with aftershock discrimination [WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: HIGH, Rationale: This conclusion accurately synthesizes findings from multiple sources. The absence of direct cross-reference for modern events is documented in KB:03_cross_reference_findings.md "What Was NOT Found" and KB:README.md main finding. The qualifier "despite substantial data sharing" is supported by KB:02_isc_bulletin_api.md documenting NEIC contributing "about one-third of all data used by the ISC" and KB:03_cross_reference_findings.md documenting ISF file sharing. The ISC-GEM historical integration (1900-2010) and iscgem identifier system is validated by KB:01_usgs_comcat_api.md listing incorporated catalogs and the Tohoku earthquake example from WEB:https://earthquake.usgs.gov/fdsnws/event/1/query demonstrating iscgem16461282 structure. The nearest neighbor algorithm's >97% reliability statistic is directly from the Frontiers article WebFetch: "Achieved >97% duplicate identification reliability." The characterization as "scientifically validated alternative to 'arbitrary threshold' approach" references the original task requirement to avoid "inventing arbitrary thresholds" and contrasts it with the peer-reviewed, empirically validated methodology from Frontiers in Earth Science. All major claims are substantiated.]

The practical implication for database management is clear: merging 627,000 USGS events with 1.5 million ISC events requires implementing the nearest neighbor algorithm with seismotectonic context rather than relying on simple distance/time cutoffs. ObsPy provides the computational infrastructure for this task, but the matching logic must incorporate magnitude consistency, bidirectional time differences, and declustering to avoid the catastrophic failures observed with naive threshold-based approaches [WEB:https://www.researchgate.net/publication/259742624_ObsPy_A_Python_Toolbox_for_Seismology][WEB:https://frontiersin.org/articles/10.3389/feart.2022.820277/full].^[Verdict: TRUE, Confidence: MEDIUM, Rationale: The database scale (627K USGS, 1.5M ISC) is from the original task file defining the research scope. The recommendation to use nearest neighbor algorithm over "simple distance/time cutoffs" is supported by the Frontiers article methodology showing superior performance (>97% reliability) compared to basic window methods. The ObsPy computational infrastructure role is documented in web search results (https://www.researchgate.net/publication/259742624_ObsPy_A_Python_Toolbox_for_Seismology) describing catalog operations and FDSN data access. The three required components (magnitude consistency, bidirectional time differences, declustering) are derived from: (1) Frontiers article discussing proximity function with magnitude consideration, (2) explicit bidirectional time criterion for duplicates vs. unidirectional aftershocks, and (3) web search results on declustering algorithms (https://link.springer.com/article/10.1007/s10462-025-11229-3). The characterization of "catastrophic failures" from naive approaches references the task context describing how a previous AI "failed spectacularly by inventing arbitrary thresholds." Confidence is MEDIUM because while individual components are supported, the integrated recommendation synthesizes multiple sources into a practical workflow not explicitly validated as a complete system in any single source.]
